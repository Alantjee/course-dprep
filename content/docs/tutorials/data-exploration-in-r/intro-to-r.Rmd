---
title: "Data exploration in R (dPrep)"
author: "Data Challenge 1"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyverse)

```

*In this data challenge, we'll walk you through the steps of exploring a data set and obtaining an understanding about the setting in which data was collected.*

*We've chosen a data set used by [Sim et al. 2020](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3649085), in which the authors estimate the effect that COVID-19 had on music consumption on Spotify!*

*Along the way, you'll practice the skills you have been equipped with in the DataCamp tutorials.*


--- 

### Prerequisites
* [Installing R and R Studio](http://tilburgsciencehub.com/setup/r/)
* [DataCamp Introduction to R](https://www.datacamp.com/courses/free-introduction-to-r) (chapter 1, 2, 3, 4, 5)
* [DataCamp Intermediate R](https://www.datacamp.com/courses/intermediate-r) (chapter 1, 2, 3)

--- 

### Learning Objectives
- Setup R and R Studio
- Familiarize yourself with the basics in R
  - Read data from text files into data frames in R
  - Create and handle various data types in R (e.g., vector, matrix, dataframe)
  - Change the content of data frames (e.g., create, drop, or rename columns)
  - Filter data in data frames (e.g., by index, logical expressions, missing records, etc.)
  - Apply basic programming concepts (if-else statements, for-loop, functions )
- Assess data quality and obtain data understanding
  - Calculate with data (e.g., summing up numbers)
  - Generate summary statistics
  - Generate plots

--- 


### Submission 
Students are expected to hand in a digital copy of their answers and code according to the [submission guidelines](https://dprep.hannesdatta.com/#submission-guidelines). 


--- 

### Support Needed? 
For technical issues outside of scheduled classes, please check the [support section](https://dprep.hannesdatta.com/docs/course/support) on the course website.


---

### 1. Loading and inspecting the Data
[Google’s COVID-19 Community Mobility Reports](https://www.google.com/covid19/mobility/) are used extensively by governments and researchers to get an understanding about the pandemic's effect on social life and the economy. In the data, Google provides information on
*daily percentage changes* in the number of visits by place category, compared with the
corresponding day of the week during the 5-week (pre-Covid) period between January 3 and February 6, 2020. The data consists of 112,000 rows that cover six categories of places: retail & recreation, grocery & pharmacy, parks, transit stations, workplaces, and residence. 

With the help of the `read.csv()` function, we can now import the mobility data for the Netherlands into R. Download this [data set from Google](https://www.google.com/covid19/mobility/) (you have to unzip it first!), create a *new R script* in the same directory, and read in the data. 

```{r load_data}
mobility <- read.csv("2020_NL_Region_Mobility_Report.csv", sep=",")
```
\
**Exercise 1**     
Inspect the `mobility` data frame, and describe the *structure of the data set* in your own words. What is the unit of analysis at which the data is provided ("what's the grouping variable?"). How is the data sorted (if at all)? How are variables/metrics operationalized? Are the values contained in each column complete? Do these values all make sense? Are “strings” properly encoded (i.e., do they contain any weird characters, or do they seem appropriately rendered so you can read them)?

**Solution**  
The dataset shows the mobility changes at a *national, regional, and city level* in the Netherlands, for multiple categories of places. The records are sorted by date, and are grouped by location (starting with country stats). Moreover, three of the columns (`metro_area`, `iso_3166_2_code`, `census_flips_code`) contain only empty data, and two other columns (`sub_region_1`, `sub_region_2`) are blank for a subset of the values. This also holds for the columns related to percentage changes in mobility scores which are missing in some cases (especially on a city-level).

\

**Exercise 2**     
Suppose you'd like to extract data for the Netherlands as a whole (i.e., NOT at the regional or city level), how would you have to filter for it?

**Solution**  
```{r, echo = TRUE, results = 'hide'}
mobility[mobility$sub_region_1==''&mobility$sub_region_2=='',]
```

\
**Exercise 3**  
The data shows the percentage changes in visits to categorized places, compared to a normal value for that day of the week (i.e., baseline). The baseline day is the median value between January 3 and February 6, 2020. In other words, all reported numerical values are *relative to the first few weeks of 2020*. 

Think of one or more problems that can arise as a result of this methodology (even better if you come up with concrete examples that illustrate this)! 

**Solution**  
- It doesn't account for seasonality (e.g., park visits increase as the weather improves)  
- In the Netherlands, we experienced a relatively mild winter period throughout 2020 (e.g., the average temperature in January 2020 was the 3rd highest ever). As a result, the time distribution of certain categories (e.g., parks, residence) may not be representative for a typical year. 
- Probably a lot of other reasons! Try to think about more!
\

---

### 2. Data Cleaning & Transformation

\

#### Drop Columns
To make working with the data frame more manageable, we drop columns we don't need. More specifically, we overwrite the dataframe with a selection of necessary columns (e.g., `df = df[,c("col_1", "col3", "col"4", "col5", ...)])`).

\
**Exercise 4**  
Drop the columns `country_region_code`, `metro_area`, `iso_3166_2_code` and `census_fips_code` from the `mobility` dataframe. How many columns do you end up with?


**Solution**
```{r, echo = TRUE, results = 'hide'}
# bad solution - think about WHY?
mobility[, c(2:4, 8:14)]

# good solution
cols_to_drop = c('country_region_code', 'metro_area', 'iso_3166_2_code', 'census_fips_code')
mobility = mobility[, which(!colnames(mobility)%in%cols_to_drop)]
head(mobility)
```

\

#### Rename Columns
We continue with the data frame `mobility`.

As you can see below, some of the remaining column names of `mobility` are rather long (or can be described more precisely). 

```{r column_names}
 # current column names
 colnames(mobility)
```

You can rename a column of a data frame (`df`) by overwriting the current column names with a vector of new column names, like this: `colnames(df) = c("new_col_name_1", "new_col_name_2", "new_col_name_3", ...)` 

\

**Exercise 5**  
Trim the long column names (e.g., `retail_and_recreation_percent_change_from_baseline` becomes `retail_and_recreation`) and replace `sub_region_1` and `sub_region_2` by `province` and `city`, respectively. 

**Solution**
```{r}
colnames(mobility) = c("country_region", 
                       "province",
                       "city", 
                       "date", 
                       "retail_and_recreation",
                       "grocery_and_pharmacy", 
                       "parks", 
                       "transit_stations", 
                       "workplaces", 
                       "residential")

```

\

#### Convert into Date

Although the dates may look like "regular" dates (e.g., `2020-02-15`) R treats them like a character string (try running `class(mobility$date)` for yourself!). Since we want the data to be ordinal so that `2020-02-16` is placed right before `2020-02-15`, we need to convert the `date` column into date format as follows:

```{r}
mobility$date = as.Date(mobility$date)
```

\

**Exercise 6**  
What's the first and last date in our data frame? Tip: you can use `min()` and `max()` now that the date column has been converted into date format!

**Solution**
The data runs from  February 15 2020 (`min(mobility$date)`) to January 5 2021 (`max(mobility$date)`).

\

#### Adding a New Column

To get a proxy for overall movement trends, we create another column named `avg_mobility` which is the row mean of `retail_and recreation`, `grocery_and_pharmacy`, `parks`, `transit_stations`, `workplaces`, and `residential`. 


**Exercise 7**  
Add the `avg_mobility` column to your dataset (keep in mind that the data frame may contain one or more missing values). You may want to look up the documentation of the `na.rm` parameter. 


**Solution**  
```{r}
# solution (elegant, but not sustainable)
mobility$avg_mobility = rowMeans(mobility[,5:ncol(mobility)], na.rm = TRUE)

# solution (most elegant and sustainable)
selected_columns = grep('retail|grocery|park|transit|work|resident', colnames(mobility), value=T)
mobility$avg_mobility = rowMeans(mobility[,selected_columns], na.rm = TRUE)

```

```{r eval=FALSE}
# solution (least elegant - and far less efficient) - do you notice the difference in running time?  

for(counter in 1:nrow(mobility)){
  row = mobility[counter, ]
  mobility[counter, 'avg_mobility'] = mean(c(row$retail_and_recreation,
                                             row$grocery_and_pharmacy, 
                                             row$parks, 
                                             row$transit_stations, 
                                             row$workplaces, 
                                             row$residential), 
                                           na.rm=TRUE)
}

```

\

#### Selecting a Subset of Data

For analysis purposes, we prefer to split up the data frame into country, province, and city-level records. We know that the values in the `province` and `city` columns are empty for the country level stats. In the same way, the city level records are blank for the data aggregated on the province level. This is shown in the table below where each `X` denotes the availability of data in a respective column.


| Aggregation Level | country_region | province | city | 
| :----- | :----- | :----- | :----- | 
| Country | X |  | | 
| Province | X | X | | 
| City | X | X | X | 

\

**Exercise 8**  
Create three subsets (`country`, `province`, `city`) of `mobility` according to the descriptions above. To filter for empty strings (`""`) you can use the boolean expression `df$column == ""`.


**Solution**
```{r}
country = mobility[(mobility$city == "") & (mobility$province == ""),]
province = mobility[(mobility$city == "") & (mobility$province != ""),]
city = mobility[mobility$city != "",]
```

\

**Exercise 9**  
Write a function `missing_values()` that takes in a dataframe (`df`) and a vector of columns (`cols`) and calculates the percentage of missing values for each column. Using this function, fill in the table below and comment on your findings. 

| subset | retail_and_recreation | grocery_and_pharmacy | parks | transit_stations | workplaces | residential | 
| :--- |:--- |:--- |:--- |:--- |:--- |:--- |
| `country` | | | | | | | 
| `province` | | | | | | | 
| `city` | |  | | | | |

**Solution**
```{r eval=FALSE}
# less elegant solution
missing_values <- function(df, cols){
  perc = NULL
  for(column in cols){
    perc[length(perc) + 1] = round(mean(is.na(df[,column])) * 100, 2)
  }
  return(perc)
}

# obtain column indexes
cols = grep('retail|grocery|park|transit|work|resident', colnames(mobility), value = T)

missing_values(country, cols)
missing_values(province, cols)
missing_values(city, cols)

# more elegant solution
missing_values <- function(df, cols) {
  sapply(cols, function(x) 100*length(which(is.na(df[,x])))/nrow(df))
}
missing_values(country, cols)
missing_values(province, cols)
missing_values(city, cols)

```

The lower the aggregation level, the higher the percentage of missing records (especially parks). Further inspection of the [documentation](https://support.google.com/covid19-mobility/answer/9825414?hl=en&ref_topic=9822927) tells us that these data gaps are intentional because the data doesn't meet the quality and privacy threshold. 

| subset | retail_and_recreation | grocery_and_pharmacy | parks | transit_stations | workplaces | residential | 
| :--- |:--- |:--- |:--- |:--- |:--- |:--- |
| `country` | 0 | 0 | 0 | 0 | 0 | 0 | 
| `province` | 0.49 | 0.08 | 7.34 | 1.02 | 0.23 | 0 | 
| `city` | 44.32 | 37.65| 82.40 | 45.11 | 6.43 | 45.39 |

\

### 3. Data Exploration

\

Now that the data is in the right shape, it's finally time to analyze it! You can easily visualize the data with the built-in `plot()` function. It takes the following input parameters:   

- `x` = the horizontal values  
- `y` = vertical values  
- `col` = color of the fill  (optional)
- `type` = `l` is a line chart, `p` is a scatter plot (optional)  

Here's an example of a time-series plot of the number of visits to parks: 

```{r}
plot(x = country$date, # horizontal
     y = country$parks, # vertical
     col = "green", # color
     type = "l") # line chart 
```

And here's another one that shows how to plot two lines in one graph:

```{r}
plot(x = country$date, # horizontal
     y = country$residential, # vertical
     col = "red", # color of chart
     type = "l",  # line chart
     ylim = c(-80, 30), # range of vertical axis
     ylab = "% change from baseline", # label of vertical axis
     xlab = "", # no label of horizontal axis
     main = "Less time at work partially compensated by more time at home") # plot title

lines(country$date, country$workplaces, col="blue") # add a second line chart

legend("bottomleft", c("residential", "workplace"), fill=c("red", "blue")) # legend (location, names, colors)
```

The aim of this assignment is to further explore the data on your own. Spot interesting patterns, visualize the relationships and provide a brief write-up of your analysis. Here are a couple of ideas you may want to look into, but feel more than welcome to add your own ones!

- The southern provinces of the Netherlands initially suffered the most from COVID-19 in terms of the number of positive cases (possibly due to [carnival](https://dutchreview.com/news/first-man-to-get-coronavirus-covid-19-in-the-netherlands-celebrated-carnival/)). As such, stricter policies were imposed by the government than in other parts of the country. Can you find patterns in the data that illustrate the (in)effectiveness of these measures? 

- Comparison of mobility patterns in the first and second COVID-19 wave. Did our behavior change throughout time? And how about the summer break? 

- How does your own place of residence relate to the rest of the Netherlands? (e.g., create a ranking!)

- Extract the Google Mobility statistics for *a different country*, and re-process your RMarkdown. Compare the Covid stats for these two countries.

- Of course, you can come up with your own suggestions!

