---
weight: 1
bookFlatSection: true
title: "Syllabus"
bookHidden: false
---

# Syllabus

Activities

- Data collection pitch (group) / presentation
- Legal battle + anonymization outcome
- Prototype
- Deployment as large project

session chair, presentations, pitches, discussions


## Preparation before the course starts

## During the course

- Module 0: Course overview + getting started

- Module 1a: Research and Business Opportunities From Online Data Collections
  - Design principles
  - Prep: Business
  - Prep: Research
  - Prep: Legality
  - "What I think is hot right now"

- Module 1b: Legality and Terms of Use (--> paper? advice?)

- Module 3: Web scraping
- Module 4: APIs

- Module 5: Data Management and Deployment in Production
  - Software Stack
  - Computing Infrastructure
  - Dockers
  - Structured and Unstructured databases
  - "Polishing" Code

- Module 6: Data sharing

- Presentation of research / business projects

## Meetings


## Preparation before the course starts

- Software environment setup
- Introduction to Python and Jupyter Notebook using Anaconda
- Overview about this course


## Online Tutorials (prerecorded) / "labs"

### Webscraping 101

### Webscraping Advanced

### APIs 101

### APIs Advanced

### Structured databases

### Unstructured databases

### Disclosing data / data workflow

## Web scraping

## APIs

- Software environment setup
- Introduction to Anaconda Python (Jupyter Notebook, Spyder)
- Introduction to the Glossary

## Web scraping

- Data retrieval from websites
- Application protocol interfaces
- Data/functionality/algorithm access
- API get
- API provide
- Releasing/sharing data via APIs
- Parsing

## Data management

- Database technology
- Structured: MySQL, Google BigQuery
- Unstructured: Amazon DynamoDB, MongoDB
- File-based systems
- Local: SSD, HDD
- Server/cloud: S3, FTP, Google Drive
- Per database
- Schema/design
- Extracting and writing data
- Indexing
- Maintenance
- ShinyApps / Interactive dashboards


- Scraper 1: Static scraper, single-machine, no database (two versions: either with or without browser); backward-looking versus forward-looking
- Scraper 2: Dynamic scraper, with database connection + monitoring

## Ethics

## Topics for the guide

### Web scraping

- Design principles
- Connecting to a website without browser window
- Connecting to a website with browser window
- Using headers
- Cookies and continuing existing sessions
- Identifying objects using CSS selectors
- Identifying objects using XPATH selectors
- Loop through objects
- Timing / delays
- Looping
- Planning a data collection
- Seeding
- Sampling
- Writing to CSV
- Writing to JSON

### Saving and writing locally and remotely (databases, file-based systems)
- Writing to file
- Writing to S3
- SQL - write
- SQL - read
-

Project: Data collection + auditing of data

Real-time analytics (use database (learnt here), in combination with research method (e.g., regression), to create insights in realtime

Project: collect data OR make available data/algorithm from other classes / how to run supervision?
